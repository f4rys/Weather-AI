{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8292ed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import zipfile\n",
    "import csv\n",
    "import fileinput\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b9f281",
   "metadata": {},
   "source": [
    "# Collecting data from imgw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc231d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://danepubliczne.imgw.pl/data/dane_pomiarowo_obserwacyjne/dane_meteorologiczne/dobowe/synop/'\n",
    "raw_data_folder = 'imgw_data'\n",
    "unzipped_folder = \"unzipped/\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(raw_data_folder):\n",
    "    os.makedirs(raw_data_folder)\n",
    "\n",
    "# Use wget command to download the entire public_html folder\n",
    "subprocess.call(['wget', '-r', '--no-parent', '--no-host-directories', '--cut-dirs=1',\n",
    "                    '--directory-prefix=' + raw_data_folder, '-A', 'zip', '--no-clobber', url])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6486aa9",
   "metadata": {},
   "source": [
    "# Concatenating data about Tarnów from IMGW into single CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "053e582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unpacking all zips\n",
    "\n",
    "if not os.path.exists(unzipped_folder):\n",
    "    os.mkdir(unzipped_folder)\n",
    "\n",
    "for root, dirs, files in os.walk(raw_data_folder):\n",
    "    for filename in files:\n",
    "        filepath = os.path.join(root, filename)\n",
    "\n",
    "        if zipfile.is_zipfile(filepath):\n",
    "            with zipfile.ZipFile(filepath) as zip_file:\n",
    "                zip_file.extractall(unzipped_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58cb8a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing rows from csv files not containing station \"Tarnów\"\n",
    "\n",
    "for filename in os.listdir(unzipped_folder):\n",
    "    if filename.endswith('.csv'):\n",
    "        filepath = os.path.join(unzipped_folder, filename)\n",
    "        with open(filepath, 'r', newline='') as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            rows_to_keep = [row for row in reader if row[1] == 'TARNÓW']\n",
    "        with open(filepath, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerows(rows_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ad264cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing remaining empty csv files\n",
    "\n",
    "for file_name in os.listdir(unzipped_folder):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(unzipped_folder, file_name)\n",
    "        if os.path.getsize(file_path) == 0:\n",
    "            os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84ae1a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating remaining csv files\n",
    "csv_files = [file for file in os.listdir(unzipped_folder) if file.endswith(\".csv\")]\n",
    "\n",
    "with open(\"data.csv\", \"w\", newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    for file in csv_files:\n",
    "        path = os.path.join(unzipped_folder, file)\n",
    "        with open(path, \"r\") as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            for row in reader:\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "539f5266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing \"unzipped folder\"\n",
    "shutil.rmtree('unzipped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3be581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting rows chronologically\n",
    "with open('data.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    sorted_rows = sorted(reader, key=lambda row: (int(row[2]), int(row[3]), int(row[4])))\n",
    "\n",
    "with open('data.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(sorted_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec0ed76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding headers to data.csv\n",
    "headers = ['CODE', 'NAME', 'YEAR', 'MONTH', 'DAY', 'TMAX', 'TMAX_ST', 'TMIN', 'TMIN_ST', \n",
    "           'STD', 'STD_ST', 'TMNG', 'TMNG_ST', 'SMDB', 'SMDB_ST', 'RO', 'PKSN', 'PKSN_ST', \n",
    "           'RWSN', 'RWSN_ST', 'USL', 'USL_ST', 'DESZ', 'DESZ_ST', 'SNEG', 'SNEG_ST', 'DISN', \n",
    "           'DISN_ST', 'GRAD', 'GRAD_ST', 'MGLA', 'MGLA_ST', 'ZMGL', 'ZMGL_ST', 'SADZ', \n",
    "           'SADZ_ST', 'GOLO', 'GOLO_ST', 'ZMNI', 'ZMNI_ST', 'ZMWS', 'ZMWS_ST', 'ZMET', \n",
    "           'ZMET_ST', 'FF10', 'FF10_ST', 'FF15', 'FF15_ST', 'BRZA', 'BRZA_ST', 'ROSA', \n",
    "           'ROSA_ST', 'SZRO', 'SZRO_ST', 'DZPS', 'DZPS_ST', 'DZBL', 'DZBL_ST', 'SG', \n",
    "           'IZD', 'IZD_ST', 'IZG', 'IZG_ST', 'AKTN', 'AKTN_ST']\n",
    "\n",
    "with open('data.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    data = list(csv_reader)\n",
    "\n",
    "with open('data.csv', 'w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(headers)\n",
    "    for row in data:\n",
    "        csv_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc0c50fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted unnecessary info about station.\n"
     ]
    }
   ],
   "source": [
    "#Removing columns containing station info\n",
    "input_file = 'data.csv'\n",
    "\n",
    "with fileinput.input(files=input_file, inplace=True) as f_input:\n",
    "    csv_reader = csv.reader(f_input)\n",
    "\n",
    "    for row in csv_reader:\n",
    "        updated_row = row[2:]\n",
    "\n",
    "        print(','.join(updated_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d844c2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting date into YYYY-MM-DD format\n",
    "df = pd.read_csv(\"data.csv\", low_memory=False)\n",
    "df[\"DATE\"] = pd.to_datetime(df[[\"YEAR\", \"MONTH\", \"DAY\"]])\n",
    "df.drop([\"YEAR\", \"MONTH\", \"DAY\"], axis=1, inplace=True)\n",
    "df = df[[\"DATE\"] + [col for col in df.columns if col != \"DATE\"]]\n",
    "df.to_csv(\"data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
